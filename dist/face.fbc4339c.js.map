{"mappings":"AAAA,MAAM,QAAQ,SAAS,aAAa,CAAC;AACrC,MAAM,SAAS,SAAS,aAAa,CAAC;AACtC,MAAM,MAAM,OAAO,UAAU,CAAC;AAC9B,IAAI,WAAW,GAAG;AAClB,IAAI,SAAS,GAAG;AAEhB,MAAM,aAAa,SAAS,aAAa,CAAC;AAC1C,MAAM,UAAU,WAAW,UAAU,CAAC;AACtC,MAAM,kBAAkB,OAAO,OAAO;AAEtC,eAAe;IACX,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;QACrD,OAAO;YAAE,OAAO;YAAM,QAAQ;QAAG;IACrC;IACA,MAAM,SAAS,GAAG;IAClB,MAAM,MAAM,IAAI;IAEhB,oCAAoC;IACpC,OAAO,KAAK,GAAG,MAAM,UAAU;IAC/B,OAAO,MAAM,GAAG,MAAM,WAAW;IACjC,OAAO,UAAU,GAAG,MAAM,UAAU;IACpC,OAAO,UAAU,GAAG,MAAM,WAAW;AACzC;AAEA,eAAe;IACP,wCAAwC;IACxC,MAAM,YAAY;IAElB,+CAA+C;IAC/C,MAAM,QAAQ,IAAI,CAAC,gBAAgB,CAAC,WAAW,CAAC;AAExD;AAEA,eAAe;IACX,MAAM;IAEN,MAAM,QAAQ,MAAM,gBAAgB,cAAc,CAAC,OAC/C,IAAI,gBAAgB,uBAAuB,CAAC;QAAE,WAAW;QAAK,gBAAgB;IAAI;IAGtF,MAAM,OAAO,CAAC;IACd,sBAAsB;AAC1B;AAEA,eAAe,kBAAkB,IAAI;IACjC,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,CAAC,EAAE,CAAC,EAAE,GAAG,KAAK,GAAG;IACxC,IAAI,UAAU,CAAC,GAAG,GAAG,OAAO;AAEhC;AAEA,cAAc,IAAI,CAAC;AAEnB,QAAQ,GAAG,CAAC","sources":["face-censor.js"],"sourcesContent":["const video = document.querySelector('.webcam');\r\nconst canvas = document.querySelector('.video');\r\nconst ctx = canvas.getContext('2d');\r\nctx.strokeStyle = '#00ff00';\r\nctx.lineWidth = 2;\r\n\r\nconst faceCanvas = document.querySelector('.face-detection');\r\nconst faceCtx = faceCanvas.getContext('2d');\r\nconst faceDetectorAPI = window.faceapi;\r\n\r\nasync function startWebcam() {\r\n    const stream = await navigator.mediaDevices.getUserMedia({\r\n        video: { width: 1280, height: 720},\r\n    });\r\n    video.srcObject = stream;\r\n    await video.play();\r\n\r\n    // sizing canvas to be same as video\r\n    canvas.width = video.videoWidth;\r\n    canvas.height = video.videoHeight;\r\n    canvas.faceCanvas = video.videoWidth;\r\n    canvas.faceCanvas = video.videoHeight;\r\n}\r\n\r\nasync function loadModels() {\r\n        // Use a working CDN path for the models\r\n        const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';\r\n        \r\n        // Load only the tiny face detector model first\r\n        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\r\n    \r\n}\r\n\r\nasync function detect() {\r\n    await loadModels();\r\n\r\n    const faces = await faceDetectorAPI.detectAllFaces(video, \r\n        new faceDetectorAPI.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 })\r\n    );\r\n\r\n    faces.forEach(detectAndDrawFace);\r\n    requestAnimationFrame(detect);\r\n}\r\n\r\nasync function detectAndDrawFace(face) {\r\n    const { width, height, x, y } = face.box;\r\n    ctx.strokeRect(x, y, width, height);\r\n\r\n}\r\n\r\nstartWebcam().then(detect);\r\n\r\nconsole.log(faceDetectorAPI);"],"names":[],"version":3,"file":"face.fbc4339c.js.map","sourceRoot":"/__parcel_source_root/"}